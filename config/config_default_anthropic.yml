environment:
    prompt_path: ''
    tools_file: ''
    database_folder: ''
    database_validators: ''
    task_description:  # If you don't want to infer you can simply provide it in the field 'content'
        llm:
            type: 'anthropic'
            name: 'claude-3-5-sonnet-20241022'
        extraction_prompt:
            prompt_hub_name: 'marccgrau/task_extraction'

description_generator:
    flow_config:
        prompt:
            prompt_hub_name: 'marccgrau/flows_extraction'
    policies_config:
        prompt:
            prompt_hub_name: 'marccgrau/policies_extraction'
        num_workers: 2
        timeout: 300 # in seconds
    edge_config:
        prompt:
            prompt_hub_name: 'marccgrau/policies_graph'
        num_workers: 2
        timeout: 300 # in seconds
    description_config:
        prompt:
            prompt_hub_name: 'marccgrau/description_generation'
        num_workers: 2
        timeout: 300 # in seconds
    refinement_config:
        do_refinement: False # If you don't want to refine the expected behaviour of the descriptions, set this to False
        prompt_feedback:
            prompt_hub_name: 'marccgrau/description_refinement'
        prompt_refinement:
            prompt_hub_name: 'marccgrau/refined_description'
        num_workers: 2
        timeout: 300 # in seconds
    llm_policy:
        type: 'anthropic'
        name: 'claude-3-5-sonnet-20241022'
    llm_edge:
        type: 'anthropic'
        name: 'claude-3-5-sonnet-20241022'
    llm_description:
        type: 'anthropic'
        name: 'claude-3-5-sonnet-20241022'
    llm_refinement:
        type: 'anthropic'
        name: 'claude-3-5-sonnet-20241022'

event_generator:
    symbolic_enrichment_config:
        prompt:
            prompt_hub_name: 'marccgrau/event_symbolic'
        num_workers: 2
        timeout: 300 # in seconds
    symbolic_constraints_config:
        prompt:
            prompt_hub_name: 'marccgrau/symbolic_prompt_constraints'
        num_workers: 2
        timeout: 300 # in seconds
    event_graph:
        llm:
            type: 'anthropic'
            name: 'claude-3-5-sonnet-20241022'
        prompt_restrictions:
            prompt_hub_name: 'marccgrau/filter_restrictions'
        prompt_final_res:
            prompt_hub_name: 'marccgrau/event_final'
        prompt_executors:
            prompt_hub_name: 'marccgrau/event_executor'
        num_workers: 2
        timeout: 300 # in seconds


dialog_manager:
    user_parsing_mode: 'thought' # 'thought' in case the user has thought part or 'default'
    memory_path: "memory.db"
    user_prompt:
        prompt_hub_name: 'marccgrau/user_sim'
    critique_config:
        prompt:
            prompt_hub_name: 'marccgrau/end_critique'
        llm:
            type: 'anthropic'
            name: 'claude-3-5-sonnet-20241022'
    llm_user:
        type: 'anthropic'
        name: 'claude-3-5-sonnet-20241022'
    llm_chat:
        type: 'anthropic'
        name: 'claude-3-5-sonnet-20241022'
    num_workers: 2
    timeout: 300 # in seconds
    mini_batch_size: 10
    cost_limit: 5 #In dollars, only available for openAI/Anthropic bedrock. This is only for the dialog manager part
    recursion_limit: 35

analysis:
    prompt:
        prompt_hub_name: 'marccgrau/analysis_info'
    llm:
        type: 'anthropic'
        name: 'claude-3-5-sonnet-20241022'
    num_workers: 2
    timeout: 300 # in seconds

dataset:
    name: 'dataset'
    min_difficult_level: 2
    max_difficult_level: 10
    num_samples: 100
    mini_batch_size: 10
    max_iterations: 8
    cost_limit: 5 #In dollars, only available for openAI/Anthropic bedrock. This is only for the dataset generation part




